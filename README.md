# ðŸ¦™ Run LLaMA AI Locally with Ollama

This repository provides a quick setup to run Meta's LLaMA AI models locally using [Ollama](https://ollama.com/), a simple and powerful runtime for large language models.

## âœ… Features
- Run LLaMA models (LLaMA 2, Code LLaMA, etc.) locally
- No need for complex setups
- Works on Windows, macOS, and Linux
- Simple commands using Ollama CLI

---

## ðŸš€ Installation Guide

### 1. Install Ollama

Go to the official Ollama website and download the installer for your OS:

ðŸ”— https://ollama.com/download

Install it following the instructions.

---

### 2. Run a LLaMA Model

Open a terminal and run:

```bash
ollama run llama2
